{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29e90ef0",
   "metadata": {},
   "source": [
    "--- \n",
    "**Author** : Huzaifa Ali\n",
    "\n",
    "**Email** : *huzaifaa0303@gmail.com*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2da441f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04868573",
   "metadata": {},
   "source": [
    "1. Create a DataFrame from a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adcf7983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'Name' : ['Huzaifa', 'Amina', 'Ali', 'Izza', 'Fizza'],\n",
    "    'Age' : [23,25,26,27,None],\n",
    "    'Subject' : ['Computer', 'Arts', 'Physics', 'Maths', 'Chemistry'],\n",
    "    'Marks' : [90, 70, 60, 50, None] \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9936776b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    " 2. Read a CSV into a DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43888f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a csv in order to read it later\n",
    "# Create CSV\n",
    "data.to_csv('sample_data.csv', index=False)\n",
    "\n",
    "# Explanation: \n",
    "# Index is set to false because not wanted to add index numbers to csv file, it already contain those by default \n",
    "\n",
    "# Read CSV\n",
    "data = pd.read_csv('sample_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95b23ea",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "3. Display first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5867ecb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name   Age    Subject  Marks\n",
      "0  Huzaifa  23.0   Computer   90.0\n",
      "1    Amina  25.0       Arts   70.0\n",
      "2      Ali  26.0    Physics   60.0\n",
      "3     Izza  27.0      Maths   50.0\n",
      "4    Fizza   NaN  Chemistry    NaN\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b06b0a0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "4. Fill missing values with column mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4fe7ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name       0\n",
       "Age        1\n",
       "Subject    0\n",
       "Marks      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First check if there is any missing value\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "797f18d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name   Age    Subject  Marks\n",
      "0  Huzaifa  23.0   Computer   90.0\n",
      "1    Amina  25.0       Arts   70.0\n",
      "2      Ali  26.0    Physics   60.0\n",
      "3     Izza  27.0      Maths   50.0\n",
      "4    Fizza  25.0  Chemistry   67.0\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values of column which contains numeric data with their mean \n",
    "cleaned_data = data.fillna(\n",
    "    {\n",
    "        'Age' : int(data['Age'].mean()),\n",
    "        'Marks' : int(data['Marks'].mean())\n",
    "     },\n",
    "    inplace=False\n",
    ")\n",
    "\n",
    "print(cleaned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3db3865",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "5. Sort DataFrame by a column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78c7a911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name   Age    Subject  Marks\n",
      "2      Ali  26.0    Physics   60.0\n",
      "1    Amina  25.0       Arts   70.0\n",
      "4    Fizza  25.0  Chemistry   67.0\n",
      "0  Huzaifa  23.0   Computer   90.0\n",
      "3     Izza  27.0      Maths   50.0\n"
     ]
    }
   ],
   "source": [
    "sorted_data = cleaned_data.sort_values('Name')\n",
    "\n",
    "print(sorted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2847eb9a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    " 6. Filter rows (marks > 80).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "708d0ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name   Age   Subject  Marks\n",
      "0  Huzaifa  23.0  Computer   90.0\n"
     ]
    }
   ],
   "source": [
    "filtered_data = sorted_data.query('Marks > 80')\n",
    "print(filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fa5676",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    " 7. Add pass/fail column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0212193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Data : \n",
      "      Name   Age    Subject  Marks Result\n",
      "0  Huzaifa  23.0   Computer   90.0   Pass\n",
      "1    Amina  25.0       Arts   70.0   Pass\n",
      "2      Ali  26.0    Physics   60.0   Pass\n",
      "3     Izza  27.0      Maths   50.0   Fail\n",
      "4    Fizza  25.0  Chemistry   67.0   Pass\n"
     ]
    }
   ],
   "source": [
    "cleaned_data.loc[cleaned_data['Marks'] > 50, 'Result'] = 'Pass'\n",
    "cleaned_data.loc[cleaned_data['Marks'] <= 50, 'Result'] = 'Fail'\n",
    "\n",
    "print(f'New Data : \\n{cleaned_data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42690f84",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    " 8. Group by column and compute mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d810563e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Data Value : \n",
      "Age\n",
      "23.0    90.0\n",
      "25.0    68.5\n",
      "26.0    60.0\n",
      "27.0    50.0\n",
      "Name: Marks, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "numeric_data = cleaned_data.select_dtypes(include='number')\n",
    "mean_of_numeric_data = numeric_data.groupby('Age')['Marks'].mean()\n",
    "\n",
    "print(f'Mean of Data Value : \\n{mean_of_numeric_data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be00ffad",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    " 9. Merge two DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39cd1935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First dataset:\n",
      "       Name  Score\n",
      "0  Huzaifa     88\n",
      "1    Amina     92\n",
      "2      Ali     79\n",
      "\n",
      "Second dataset:\n",
      "     Name Grade\n",
      "0    Ali     B\n",
      "1   Izza     A\n",
      "2  Fizza    B+\n"
     ]
    }
   ],
   "source": [
    "# Create first dataset\n",
    "df1 = pd.DataFrame({\n",
    "    'Name': ['Huzaifa', 'Amina', 'Ali'],\n",
    "    'Score': [88, 92, 79]\n",
    "})\n",
    "\n",
    "# Create second dataset\n",
    "df2 = pd.DataFrame({\n",
    "    'Name': ['Ali', 'Izza', 'Fizza'],\n",
    "    'Grade': ['B', 'A', 'B+']\n",
    "})\n",
    "\n",
    "print(\"First dataset:\\n\", df1)\n",
    "print(\"\\nSecond dataset:\\n\", df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00978f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name  Score Grade\n",
      "0  Ali     79     B\n"
     ]
    }
   ],
   "source": [
    "# by default merge\n",
    "new_df = df1.merge(df2)\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c6302e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Score'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_12188\\2595033502.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# to get all rows of data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m new_df_all_rows = pd.merge(df1, df2, how=\u001b[33m'outer'\u001b[39m, on=\u001b[33m'Score'\u001b[39m)\n\u001b[32m      3\u001b[39m print(new_df_all_rows)\n",
      "\u001b[32mc:\\Users\\Acer\\Documents\\practice\\AL_ML_practice\\venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    166\u001b[39m             validate=validate,\n\u001b[32m    167\u001b[39m             copy=copy,\n\u001b[32m    168\u001b[39m         )\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m         op = _MergeOperation(\n\u001b[32m    171\u001b[39m             left_df,\n\u001b[32m    172\u001b[39m             right_df,\n\u001b[32m    173\u001b[39m             how=how,\n",
      "\u001b[32mc:\\Users\\Acer\\Documents\\practice\\AL_ML_practice\\venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    790\u001b[39m             self.right_join_keys,\n\u001b[32m    791\u001b[39m             self.join_names,\n\u001b[32m    792\u001b[39m             left_drop,\n\u001b[32m    793\u001b[39m             right_drop,\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m         ) = self._get_merge_keys()\n\u001b[32m    795\u001b[39m \n\u001b[32m    796\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m left_drop:\n\u001b[32m    797\u001b[39m             self.left = self.left._drop_labels_or_levels(left_drop)\n",
      "\u001b[32mc:\\Users\\Acer\\Documents\\practice\\AL_ML_practice\\venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1294\u001b[39m                         \u001b[38;5;66;03m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[32m   1295\u001b[39m                         \u001b[38;5;66;03m#  the latter of which will raise\u001b[39;00m\n\u001b[32m   1296\u001b[39m                         rk = cast(Hashable, rk)\n\u001b[32m   1297\u001b[39m                         \u001b[38;5;28;01mif\u001b[39;00m rk \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1298\u001b[39m                             right_keys.append(right._get_label_or_level_values(rk))\n\u001b[32m   1299\u001b[39m                         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1300\u001b[39m                             \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[32m   1301\u001b[39m                             right_keys.append(right.index._values)\n",
      "\u001b[32mc:\\Users\\Acer\\Documents\\practice\\AL_ML_practice\\venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1907\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1908\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1909\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1910\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1912\u001b[39m \n\u001b[32m   1913\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1914\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'Score'"
     ]
    }
   ],
   "source": [
    "# to get all rows of data\n",
    "new_df_all_rows = pd.merge(df1, df2, how='outer')\n",
    "print(new_df_all_rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
